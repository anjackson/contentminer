{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ContentMine Toolkit\n",
    "\n",
    "## Introduction\n",
    "\n",
    "These notebooks aim to provide an introduction to some of the tools in the [ContentMine](http://contentmine.org/) toolkit.\n",
    "\n",
    "<p style=\"text-align: center; background-color: lightyellow;\">\n",
    "    These <a href=\"https://jupyter.org/\">Juypter Notebooks</a> provide an interactive environment where you can run Python scripts and shell commands and see the results in your browser.<br/>\n",
    "    For shell commands, each line starts with a <tt>!</tt>, so <tt>!echo hello</tt> runs a shell script, but <tt>print('hello')</tt> runs as Python.<br/>\n",
    "    For a more detailed introduction, try this <a href=\"https://programminghistorian.org/en/lessons/jupyter-notebooks\">Introduction to Jupyter Notebooks</a>.\n",
    "</p>\n",
    "            \n",
    "### The Big Picture\n",
    "\n",
    "The vison that drives ContentMine is that text and data mining should be used to open up all research literature, allowing the factual content to be made available to all, and helping researchers to make better use of what has already been discovered.\n",
    "\n",
    "### Overall Approach\n",
    "\n",
    "The high-level workflow for meeting this vision works as follows.\n",
    "\n",
    "Given a research question or area of interest:\n",
    "\n",
    "- Collect all relevant publications:\n",
    "    - This may be as PDF files or as XML or HTML.\n",
    "- Normalise the publications into a better machine-readable form:\n",
    "    - Ideally, well-structured HTML (referred to here as 'scholarly HTML', but ntoe that this does _not_ refer to [the proposed Scholarly HTML standard](https://w3c.github.io/scholarly-html/)). _TBA what does the \"HTML subset in [JATS](https://jats.nlm.nih.gov/)\" mean?_\n",
    "    - If HTML isn't an option, plain text can be used.\n",
    "    - However, depending on the question at hand, other formats might be required.\n",
    "- Extract facts:\n",
    "    - Which papers mention which terms and concepts?\n",
    "    - What research cited in each paper?\n",
    "    - Which chemical compounds appear in the diagrams of each paper.\n",
    "- Share the results:\n",
    "    - Make the normalised publications available (if licensing permits).\n",
    "    - Make the extracted facts openly available (factual assertions and [non-consumptive datasets](https://www.hathitrust.org/htrc_ncup) can usually be made available without restriction).\n",
    "    - Create visualisations and documentation to help understand the results.\n",
    "- Make new knowledge:\n",
    "    - Use the results as the foundation for your own research.\n",
    "\n",
    "Here, however, we'll focus on a specific use case and use that to explore how the approach works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The openVirus Project\n",
    "\n",
    "In response to the COVID-19 epidemic, the [openVirus project](https://github.com/petermr/openVirus#openvirus) aims to aggregate scholarly publications and extracted knowledge on viruses and epidemics.\n",
    "\n",
    "Here, we'll look at the specific case of finding which open access electronic theses mention terms relating to viruses and epidemics. Information about UK e-theses has been gathered by the [EThOS service](https://ethos.bl.uk/), and a suitable source dataset has been made available [here](https://data.bl.uk/ethos/).\n",
    "\n",
    "The specific workflow here is:\n",
    "\n",
    "- Use the EThOS dataset to find open-access theses.\n",
    "- Get the PDFs and assemble them into the file folder layout conventions of the ContentMine toolkit.\n",
    "- Generate HTML or text versions of the PDFs.\n",
    "- Search through the HTML for the relevant terms, and extract the terms along with snippets of text as context for each time the terms appear.\n",
    "\n",
    "The openVirus project has already created some [dictionaries](https://github.com/petermr/openVirus/tree/master/dictionaries) that can be used to link the terms that appear in the text to the relevant WikiData entities. _TBA come back to dictionary creation later on_\n",
    "\n",
    "But to get started, we need some data sources. We'll start with a single theses, found by searching EThOS for relevant terms: [TraVerse : a method of natural respiratory virus transmission from symptomatic children to healthy young adults](https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.755301) (`id: uk.bl.ethos.755301`)\n",
    "\n",
    "This command was used to create the initial folder structure:\n",
    "\n",
    "    ami-makeproject -p ethos --rawfiletypes pdf\n",
    "\n",
    "Resulting in a folder called `ethos` containing a JSON project file:\n",
    "\n",
    "```\n",
    "ethos/make_project.json\n",
    "```\n",
    "\n",
    "We then add the full text, as per the expected folder layout (called the [CProject](https://github.com/ContentMine/workshop-resources/blob/master/software-tutorials/cproject/README.md) naming conventions). Listing all files shows:\n",
    "\n",
    "```\n",
    "ethos/make_project.json\n",
    "ethos/uk.bl.ethos.755301/\n",
    "ethos/uk.bl.ethos.755301/fulltext.pdf\n",
    "```\n",
    "\n",
    "If you run the following code, it will display the PDF via your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame,display\n",
    "\n",
    "display(IFrame(src=\"ethos/uk.bl.ethos.755301/fulltext.pdf\", width=\"60%\", height=\"300px\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to perform the dictionary analysis we need either a plain text version in a file called:\n",
    "\n",
    "```\n",
    "ethos/uk.bl.ethos.755301/fulltext.pdf.txt\n",
    "```\n",
    "\n",
    "Or a HTML version in a file called:\n",
    "\n",
    "```\n",
    "ethos/uk.bl.ethos.755301/scholarly.html\n",
    "```\n",
    "\n",
    "The ContentMine toolkit provide wrappers for some sophisticated tools for performing PDF-to-HTML conversion, but for our purposes we can start with a simple HTML version generated by [Apache Tika](https://tika.apache.org/).\n",
    "\n",
    "The following sequence of shell command can be used to generate a suitable HTML version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Converting to HTML using Apache Tika...\"\n",
    "!java -jar /opt/tika.jar ethos/uk.bl.ethos.755301/fulltext.pdf > ethos/uk.bl.ethos.755301/scholarly.html\n",
    "!echo \"DONE!\"\n",
    "!ls -l ethos/uk.bl.ethos.755301/scholarly.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've re-run the script above, the simple HTML this process generated can be viewed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame,display\n",
    "\n",
    "display(IFrame(src=\"ethos/uk.bl.ethos.755301/scholarly.html\", width=\"60%\", height=\"300px\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have HTML, we can finally extract some facts! We use the `ami-search` tool from the ContentMine [AMI3](https://github.com/petermr/ami3) project, which takes dictionaries of keywords relating to specific concepts and records where they appear in a set of texts.\n",
    "\n",
    "The arguments specify:\n",
    "\n",
    "- `-p ethos` to specify which project to process,\n",
    "- `--forcemake` to make sure the output is regenerated even if the output files already exist,\n",
    "- followed by a list of dictionaries to use, in this case `virus_topics` and `virus_systemic_diseases`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ami-search -p ethos --forcemake --dictionary=virus_topics --dictionary=viral_systemic_diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look in the `ethos` folder we can see all the new files created by the `ami-search` process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find ethos -type f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TBA look at the results..._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(src=\"ethos/uk.bl.ethos.755301/results/search/virus_topics/results.xml\", width=\"100%\", height=\"300px\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG,display\n",
    "display(SVG(filename='ethos/__cooccurrence/allPlots.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
